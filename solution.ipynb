{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'simple_facerec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mface_recognition\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msimple_facerec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleFacerec\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'simple_facerec'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "from simple_facerec import SimpleFacerec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepface\n",
      "  Downloading deepface-0.0.93-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: requests>=2.27.1 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from deepface) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from deepface) (2.0.1)\n",
      "Requirement already satisfied: pandas>=0.23.4 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from deepface) (2.2.3)\n",
      "Collecting gdown>=3.10.1 (from deepface)\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.30.0 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from deepface) (4.67.1)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from deepface) (11.0.0)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from deepface) (4.10.0.84)\n",
      "Requirement already satisfied: tensorflow>=1.9.0 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from deepface) (2.18.0)\n",
      "Requirement already satisfied: keras>=2.2.0 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from deepface) (3.8.0)\n",
      "Collecting Flask>=1.1.2 (from deepface)\n",
      "  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting flask-cors>=4.0.1 (from deepface)\n",
      "  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting mtcnn>=0.1.0 (from deepface)\n",
      "  Downloading mtcnn-0.1.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting retina-face>=0.0.1 (from deepface)\n",
      "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting fire>=0.4.0 (from deepface)\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gunicorn>=20.1.0 (from deepface)\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: termcolor in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from fire>=0.4.0->deepface) (2.5.0)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from Flask>=1.1.2->deepface) (3.1.5)\n",
      "Collecting itsdangerous>=2.2 (from Flask>=1.1.2->deepface)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from Flask>=1.1.2->deepface) (8.1.7)\n",
      "Collecting blinker>=1.9 (from Flask>=1.1.2->deepface)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from Flask>=1.1.2->deepface) (8.5.0)\n",
      "Collecting beautifulsoup4 (from gdown>=3.10.1->deepface)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from gdown>=3.10.1->deepface) (3.16.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from gunicorn>=20.1.0->deepface) (24.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from keras>=2.2.0->deepface) (2.1.0)\n",
      "Requirement already satisfied: rich in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from keras>=2.2.0->deepface) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from keras>=2.2.0->deepface) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from keras>=2.2.0->deepface) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from keras>=2.2.0->deepface) (0.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from pandas>=0.23.4->deepface) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from pandas>=0.23.4->deepface) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from pandas>=0.23.4->deepface) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from requests>=2.27.1->deepface) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from requests>=2.27.1->deepface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from requests>=2.27.1->deepface) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from requests>=2.27.1->deepface) (2024.12.14)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorflow>=1.9.0->deepface) (2.18.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (5.29.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (0.31.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tqdm>=4.30.0->deepface) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from importlib-metadata>=3.6->Flask>=1.1.2->deepface) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from Jinja2>=3.1.2->Flask>=1.1.2->deepface) (3.0.2)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown>=3.10.1->deepface)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown>=3.10.1->deepface)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from rich->keras>=2.2.0->deepface) (2.18.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (0.44.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\rvpsy\\anaconda3\\envs\\yolov9\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow>=1.9.0->deepface) (0.7.2)\n",
      "Downloading deepface-0.0.93-py3-none-any.whl (108 kB)\n",
      "Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.3 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.3/2.3 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.3 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114262 sha256=c2a0ec12418bcfdeda643bbecc46a33815e8f9935935906d272c8e1317d8991e\n",
      "  Stored in directory: c:\\users\\rvpsy\\appdata\\local\\pip\\cache\\wheels\\3b\\ee\\ac\\319a7b7f331f61050d0d54425079b2a883b445be3c7284a4eb\n",
      "Successfully built fire\n",
      "Installing collected packages: soupsieve, PySocks, itsdangerous, gunicorn, fire, blinker, Flask, beautifulsoup4, gdown, flask-cors, mtcnn, retina-face, deepface\n",
      "Successfully installed Flask-3.1.0 PySocks-1.7.1 beautifulsoup4-4.12.3 blinker-1.9.0 deepface-0.0.93 fire-0.7.0 flask-cors-5.0.0 gdown-5.2.0 gunicorn-23.0.0 itsdangerous-2.2.0 mtcnn-0.1.1 retina-face-0.0.17 soupsieve-2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 encoding images found.\n",
      "Encoding images loaded\n"
     ]
    }
   ],
   "source": [
    "sfr = SimpleFacerec()\n",
    "sfr.load_encoding_images(\"photos/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()  \u001b[38;5;66;03m# Capture frame-by-frame\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     face_locations , face_names \u001b[38;5;241m=\u001b[39m \u001b[43msfr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_known_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m face_loc , name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(face_locations,face_names):\n\u001b[0;32m     12\u001b[0m         y1,x2,y2,x1 \u001b[38;5;241m=\u001b[39m face_loc[\u001b[38;5;241m0\u001b[39m],face_loc[\u001b[38;5;241m1\u001b[39m],face_loc[\u001b[38;5;241m2\u001b[39m],face_loc[\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Ali\\Anaconda3\\envs\\ml\\lib\\site-packages\\simple_facerec.py:48\u001b[0m, in \u001b[0;36mSimpleFacerec.detect_known_faces\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     46\u001b[0m rgb_small_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(small_frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     47\u001b[0m face_locations \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_locations(rgb_small_frame)\n\u001b[1;32m---> 48\u001b[0m face_encodings \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_encodings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_small_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mface_locations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m face_names \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m face_encoding \u001b[38;5;129;01min\u001b[39;00m face_encodings:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# See if the face is a match for the known face(s)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ali\\Anaconda3\\envs\\ml\\lib\\site-packages\\face_recognition\\api.py:214\u001b[0m, in \u001b[0;36mface_encodings\u001b[1;34m(face_image, known_face_locations, num_jitters, model)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m raw_landmarks \u001b[38;5;241m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [np\u001b[38;5;241m.\u001b[39marray(face_encoder\u001b[38;5;241m.\u001b[39mcompute_face_descriptor(face_image, raw_landmark_set, num_jitters)) \u001b[38;5;28;01mfor\u001b[39;00m raw_landmark_set \u001b[38;5;129;01min\u001b[39;00m raw_landmarks]\n",
      "File \u001b[1;32mc:\\Users\\Ali\\Anaconda3\\envs\\ml\\lib\\site-packages\\face_recognition\\api.py:214\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m raw_landmarks \u001b[38;5;241m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_face_descriptor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_landmark_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_jitters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m raw_landmark_set \u001b[38;5;129;01min\u001b[39;00m raw_landmarks]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Open the camera (0 for default camera, or 1 for external camera)\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# Infinite loop to continuously capture frames\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()  # Capture frame-by-frame\n",
    "    face_locations , face_names = sfr.detect_known_faces(frame)\n",
    "    for face_loc , name in zip(face_locations,face_names):\n",
    "        y1,x2,y2,x1 = face_loc[0],face_loc[1],face_loc[2],face_loc[3]\n",
    "        cv2.putText(frame,name,(x1,y1-10),cv2.FONT_HERSHEY_DUPLEX,1,(0,0,200),2)\n",
    "        cv2.rectangle(frame,(x1,y1),(x2,y2),(0,0,200),4)\n",
    "    if not ret:  # If the frame is not captured correctly, break the loop\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "    \n",
    "    # Display the frame in a window named \"Frame\"\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Wait for 1 millisecond and check if the 'Esc' key is pressed (ASCII for Esc is 27)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # 27 is the escape key\n",
    "        break\n",
    "\n",
    "# Release the capture and close the window when done\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 encoding images found.\n",
      "Encoding images loaded\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"photos\\cr1.jpg\")\n",
    "rgb_img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "img_encoding = face_recognition.face_encodings(rgb_img)[0]\n",
    "img2 = cv2.imread(\"photos\\messi2.jfif\")\n",
    "rgb_img2 = cv2.cvtColor(img2,cv2.COLOR_BGR2RGB)\n",
    "img_encoding2 = face_recognition.face_encodings(rgb_img2)[0]\n",
    "result = face_recognition.compare_faces([img_encoding],img_encoding2)\n",
    "print(result)\n",
    "cv2.imshow(\"img\",img)\n",
    "cv2.imshow(\"img2\",img2)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\RVPsy\\AppData\\Local\\Temp\\ipykernel_14820\\1344978358.py\", line 56, in identify_faces\n",
      "    img = face_recognition.load_image_file(file_path)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\face_recognition\\api.py\", line 86, in load_image_file\n",
      "    im = PIL.Image.open(file)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\PIL\\Image.py\", line 3465, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "PermissionError: [Errno 13] Permission denied: 'faces_data\\\\ali'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\RVPsy\\AppData\\Local\\Temp\\ipykernel_14820\\1344978358.py\", line 56, in identify_faces\n",
      "    img = face_recognition.load_image_file(file_path)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\face_recognition\\api.py\", line 86, in load_image_file\n",
      "    im = PIL.Image.open(file)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\PIL\\Image.py\", line 3465, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "PermissionError: [Errno 13] Permission denied: 'faces_data\\\\ali'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog, messagebox\n",
    "import os\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "\n",
    "# Directory to store captured faces\n",
    "DATA_DIR = \"faces_data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Function to capture face and name\n",
    "def capture_face():\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter your name:\")\n",
    "    if not name:\n",
    "        messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    messagebox.showinfo(\"Info\", \"Press 'c' to capture your face and 'q' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\").detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Capture Face\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('c') and len(faces) > 0:\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            face_path = os.path.join(DATA_DIR, f\"{name}.jpg\")\n",
    "            cv2.imwrite(face_path, face)\n",
    "            messagebox.showinfo(\"Success\", f\"Face saved for {name}.\")\n",
    "            break\n",
    "        elif key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to identify faces live\n",
    "def identify_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    # Load known faces\n",
    "    for file_name in os.listdir(DATA_DIR):\n",
    "        file_path = os.path.join(DATA_DIR, file_name)\n",
    "        img = face_recognition.load_image_file(file_path)\n",
    "        encoding = face_recognition.face_encodings(img)\n",
    "        if encoding:\n",
    "            known_faces.append(encoding[0])\n",
    "            known_names.append(os.path.splitext(file_name)[0])\n",
    "\n",
    "    if not known_faces:\n",
    "        messagebox.showerror(\"Error\", \"No faces found. Please capture some faces first.\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    messagebox.showinfo(\"Info\", \"Press 'q' to quit live recognition.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            matches = face_recognition.compare_faces(known_faces, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            if True in matches:\n",
    "                first_match_index = matches.index(True)\n",
    "                name = known_names[first_match_index]\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Live Face Recognition\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# GUI Application\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Face Recognition System\")\n",
    "\n",
    "    capture_button = tk.Button(root, text=\"Capture Face\", command=capture_face, width=30, height=2)\n",
    "    capture_button.pack(pady=20)\n",
    "\n",
    "    recognize_button = tk.Button(root, text=\"Identify Faces\", command=identify_faces, width=30, height=2)\n",
    "    recognize_button.pack(pady=20)\n",
    "\n",
    "    exit_button = tk.Button(root, text=\"Exit\", command=root.quit, width=30, height=2)\n",
    "    exit_button.pack(pady=20)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\RVPsy\\AppData\\Local\\Temp\\ipykernel_8748\\2375300119.py\", line 57, in identify_faces\n",
      "    img = face_recognition.load_image_file(file_path)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\face_recognition\\api.py\", line 86, in load_image_file\n",
      "    im = PIL.Image.open(file)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\PIL\\Image.py\", line 3465, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "PermissionError: [Errno 13] Permission denied: 'faces_data\\\\ali'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\RVPsy\\AppData\\Local\\Temp\\ipykernel_8748\\2375300119.py\", line 57, in identify_faces\n",
      "    img = face_recognition.load_image_file(file_path)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\face_recognition\\api.py\", line 86, in load_image_file\n",
      "    im = PIL.Image.open(file)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\PIL\\Image.py\", line 3465, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "PermissionError: [Errno 13] Permission denied: 'faces_data\\\\ali'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\RVPsy\\AppData\\Local\\Temp\\ipykernel_8748\\2375300119.py\", line 57, in identify_faces\n",
      "    img = face_recognition.load_image_file(file_path)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\face_recognition\\api.py\", line 86, in load_image_file\n",
      "    im = PIL.Image.open(file)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\PIL\\Image.py\", line 3465, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "PermissionError: [Errno 13] Permission denied: 'faces_data\\\\ali'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\RVPsy\\AppData\\Local\\Temp\\ipykernel_8748\\2375300119.py\", line 57, in identify_faces\n",
      "    img = face_recognition.load_image_file(file_path)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\face_recognition\\api.py\", line 86, in load_image_file\n",
      "    im = PIL.Image.open(file)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\PIL\\Image.py\", line 3465, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "PermissionError: [Errno 13] Permission denied: 'faces_data\\\\ali'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\RVPsy\\AppData\\Local\\Temp\\ipykernel_8748\\2375300119.py\", line 57, in identify_faces\n",
      "    img = face_recognition.load_image_file(file_path)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\face_recognition\\api.py\", line 86, in load_image_file\n",
      "    im = PIL.Image.open(file)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\PIL\\Image.py\", line 3465, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "PermissionError: [Errno 13] Permission denied: 'faces_data\\\\ali'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\RVPsy\\AppData\\Local\\Temp\\ipykernel_8748\\2375300119.py\", line 57, in identify_faces\n",
      "    img = face_recognition.load_image_file(file_path)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\face_recognition\\api.py\", line 86, in load_image_file\n",
      "    im = PIL.Image.open(file)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\PIL\\Image.py\", line 3465, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "PermissionError: [Errno 13] Permission denied: 'faces_data\\\\ali'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\RVPsy\\AppData\\Local\\Temp\\ipykernel_8748\\2375300119.py\", line 57, in identify_faces\n",
      "    img = face_recognition.load_image_file(file_path)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\face_recognition\\api.py\", line 86, in load_image_file\n",
      "    im = PIL.Image.open(file)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\PIL\\Image.py\", line 3465, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "PermissionError: [Errno 13] Permission denied: 'faces_data\\\\ali'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\RVPsy\\AppData\\Local\\Temp\\ipykernel_8748\\2375300119.py\", line 57, in identify_faces\n",
      "    img = face_recognition.load_image_file(file_path)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\face_recognition\\api.py\", line 86, in load_image_file\n",
      "    im = PIL.Image.open(file)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\PIL\\Image.py\", line 3465, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "PermissionError: [Errno 13] Permission denied: 'faces_data\\\\ali'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\RVPsy\\AppData\\Local\\Temp\\ipykernel_8748\\2375300119.py\", line 57, in identify_faces\n",
      "    img = face_recognition.load_image_file(file_path)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\face_recognition\\api.py\", line 86, in load_image_file\n",
      "    im = PIL.Image.open(file)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\PIL\\Image.py\", line 3465, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "PermissionError: [Errno 13] Permission denied: 'faces_data\\\\ali'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 114\u001b[0m\n\u001b[0;32m    111\u001b[0m     root\u001b[38;5;241m.\u001b[39mmainloop()\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 114\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 111\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    109\u001b[0m exit_button \u001b[38;5;241m=\u001b[39m tk\u001b[38;5;241m.\u001b[39mButton(root, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExit\u001b[39m\u001b[38;5;124m\"\u001b[39m, command\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: root\u001b[38;5;241m.\u001b[39mdestroy(), width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    110\u001b[0m exit_button\u001b[38;5;241m.\u001b[39mpack(pady\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m--> 111\u001b[0m \u001b[43mroot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\tkinter\\__init__.py:1429\u001b[0m, in \u001b[0;36mMisc.mainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog, messagebox\n",
    "import os\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "\n",
    "# Directory to store captured faces\n",
    "DATA_DIR = \"faces_data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Function to capture face and name\n",
    "def capture_face():\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter your name:\")\n",
    "    if not name:\n",
    "        messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    messagebox.showinfo(\"Info\", \"The system will automatically capture 15 frames of your face.\")\n",
    "\n",
    "    count = 0\n",
    "    while count < 15:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\").detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            face_path = os.path.join(DATA_DIR, f\"{name}_{count}.jpg\")\n",
    "            cv2.imwrite(face_path, face)\n",
    "            count += 1\n",
    "            if count >= 15:\n",
    "                break\n",
    "\n",
    "        cv2.imshow(\"Capture Face\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    messagebox.showinfo(\"Success\", f\"Captured 15 frames for {name}.\")\n",
    "\n",
    "# Function to identify faces live\n",
    "def identify_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    # Load known faces\n",
    "    for file_name in os.listdir(DATA_DIR):\n",
    "        file_path = os.path.join(DATA_DIR, file_name)\n",
    "        img = face_recognition.load_image_file(file_path)\n",
    "        encoding = face_recognition.face_encodings(img)\n",
    "        if encoding:\n",
    "            known_faces.append(encoding[0])\n",
    "            known_names.append(os.path.splitext(file_name)[0].rsplit('_', 1)[0])\n",
    "\n",
    "    if not known_faces:\n",
    "        messagebox.showerror(\"Error\", \"No faces found. Please capture some faces first.\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    messagebox.showinfo(\"Info\", \"Press 'q' to quit live recognition.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            matches = face_recognition.compare_faces(known_faces, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            if True in matches:\n",
    "                first_match_index = matches.index(True)\n",
    "                name = known_names[first_match_index]\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Live Face Recognition\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# GUI Application\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Face Recognition System\")\n",
    "\n",
    "    capture_button = tk.Button(root, text=\"Capture Face\", command=capture_face, width=30, height=2)\n",
    "    capture_button.pack(pady=20)\n",
    "\n",
    "    recognize_button = tk.Button(root, text=\"Identify Faces\", command=identify_faces, width=30, height=2)\n",
    "    recognize_button.pack(pady=20)\n",
    "\n",
    "    exit_button = tk.Button(root, text=\"Exit\", command=lambda: root.destroy(), width=30, height=2)\n",
    "    exit_button.pack(pady=20)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n",
      "Error sending data to Supabase: {'code': '42501', 'details': None, 'hint': None, 'message': 'new row violates row-level security policy for table \"faces\"'}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog, messagebox\n",
    "import os\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "from supabase import create_client, Client\n",
    "\n",
    "# Supabase configuration\n",
    "SUPABASE_URL = \"https://puhexttrixwbmbmokekb.supabase.co\"\n",
    "SUPABASE_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InB1aGV4dHRyaXh3Ym1ibW9rZWtiIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzM2NzAwMTcsImV4cCI6MjA0OTI0NjAxN30.3SLnBspTZB0XA97d5rjrTpkV_JsFEmwRB9eXeULBdYY\"\n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_API_KEY)\n",
    "\n",
    "# Directory to store captured faces\n",
    "DATA_DIR = \"faces_data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Function to send data to Supabase\n",
    "def send_to_supabase(name, access):\n",
    "    try:\n",
    "        response = supabase.table(\"faces\").insert({\"name\": name, \"access\": access}).execute()\n",
    "        if response.get(\"status_code\", 200) != 200:\n",
    "            raise Exception(response.get(\"message\", \"Failed to send data to Supabase\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending data to Supabase: {e}\")\n",
    "\n",
    "# Function to capture face and name\n",
    "def capture_face():\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter your name:\")\n",
    "    if not name:\n",
    "        messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    messagebox.showinfo(\"Info\", \"The system will automatically capture 15 frames of your face.\")\n",
    "\n",
    "    count = 0\n",
    "    while count < 15:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\").detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            face_path = os.path.join(DATA_DIR, f\"{name}_{count}.jpg\")\n",
    "            cv2.imwrite(face_path, face)\n",
    "            count += 1\n",
    "            if count >= 15:\n",
    "                break\n",
    "\n",
    "        cv2.imshow(\"Capture Face\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    messagebox.showinfo(\"Success\", f\"Captured 15 frames for {name}.\")\n",
    "\n",
    "# Function to identify faces live\n",
    "def identify_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    # Load known faces\n",
    "    for file_name in os.listdir(DATA_DIR):\n",
    "        file_path = os.path.join(DATA_DIR, file_name)\n",
    "        img = face_recognition.load_image_file(file_path)\n",
    "        encoding = face_recognition.face_encodings(img)\n",
    "        if encoding:\n",
    "            known_faces.append(encoding[0])\n",
    "            known_names.append(os.path.splitext(file_name)[0].rsplit('_', 1)[0])\n",
    "\n",
    "    if not known_faces:\n",
    "        messagebox.showerror(\"Error\", \"No faces found. Please capture some faces first.\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    messagebox.showinfo(\"Info\", \"Press 'q' to quit live recognition.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            matches = face_recognition.compare_faces(known_faces, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "            access = False\n",
    "\n",
    "            if True in matches:\n",
    "                first_match_index = matches.index(True)\n",
    "                name = known_names[first_match_index]\n",
    "                access = True\n",
    "\n",
    "            send_to_supabase(name, access)\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Live Face Recognition\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# GUI Application\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Face Recognition System\")\n",
    "\n",
    "    capture_button = tk.Button(root, text=\"Capture Face\", command=capture_face, width=30, height=2)\n",
    "    capture_button.pack(pady=20)\n",
    "\n",
    "    recognize_button = tk.Button(root, text=\"Identify Faces\", command=identify_faces, width=30, height=2)\n",
    "    recognize_button.pack(pady=20)\n",
    "\n",
    "    exit_button = tk.Button(root, text=\"Exit\", command=lambda: root.destroy(), width=30, height=2)\n",
    "    exit_button.pack(pady=20)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog, messagebox\n",
    "import os\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "from supabase import create_client, Client\n",
    "\n",
    "# Supabase configuration\n",
    "SUPABASE_URL = \"https://puhexttrixwbmbmokekb.supabase.co\"\n",
    "SUPABASE_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InB1aGV4dHRyaXh3Ym1ibW9rZWtiIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzM2NzAwMTcsImV4cCI6MjA0OTI0NjAxN30.3SLnBspTZB0XA97d5rjrTpkV_JsFEmwRB9eXeULBdYY\"\n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_API_KEY)\n",
    "\n",
    "# Directory to store captured faces\n",
    "DATA_DIR = \"faces_data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Function to send data to Supabase\n",
    "def send_to_supabase(name, access):\n",
    "    try:\n",
    "        response = supabase.table(\"faces\").insert({\"name\": name, \"access\": access}).execute()\n",
    "        if response.get(\"status_code\", 200) != 200:\n",
    "            raise Exception(response.get(\"message\", \"Failed to send data to Supabase\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending data to Supabase: {e}\")\n",
    "\n",
    "# Function to capture face and organize into folders\n",
    "def capture_face():\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter your name:\")\n",
    "    if not name:\n",
    "        messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "        return\n",
    "\n",
    "    user_dir = os.path.join(DATA_DIR, name)\n",
    "    os.makedirs(user_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    messagebox.showinfo(\"Info\", \"The system will automatically capture 50 frames of your face.\")\n",
    "\n",
    "    count = 0\n",
    "    while count < 50:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\").detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            face_path = os.path.join(user_dir, f\"{name}_{count}.jpg\")\n",
    "            cv2.imwrite(face_path, face)\n",
    "            count += 1\n",
    "            if count >= 15:\n",
    "                break\n",
    "\n",
    "        cv2.imshow(\"Capture Face\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    messagebox.showinfo(\"Success\", f\"Captured 50 frames for {name}.\")\n",
    "\n",
    "# Function to identify faces live\n",
    "def identify_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "\n",
    "    # Load known faces\n",
    "    for user_dir in os.listdir(DATA_DIR):\n",
    "        user_path = os.path.join(DATA_DIR, user_dir)\n",
    "        if os.path.isdir(user_path):\n",
    "            for file_name in os.listdir(user_path):\n",
    "                file_path = os.path.join(user_path, file_name)\n",
    "                img = face_recognition.load_image_file(file_path)\n",
    "                encoding = face_recognition.face_encodings(img)\n",
    "                if encoding:\n",
    "                    known_faces.append(encoding[0])\n",
    "                    known_names.append(user_dir)\n",
    "\n",
    "    if not known_faces:\n",
    "        messagebox.showerror(\"Error\", \"No faces found. Please capture some faces first.\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    messagebox.showinfo(\"Info\", \"Press 'q' to quit live recognition.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            matches = face_recognition.compare_faces(known_faces, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "            access = False\n",
    "\n",
    "            if True in matches:\n",
    "                first_match_index = matches.index(True)\n",
    "                name = known_names[first_match_index]\n",
    "                access = True\n",
    "\n",
    "            send_to_supabase(name, access)\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Live Face Recognition\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# GUI Application\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Face Recognition System\")\n",
    "\n",
    "    capture_button = tk.Button(root, text=\"Capture Face\", command=capture_face, width=30, height=2)\n",
    "    capture_button.pack(pady=20)\n",
    "\n",
    "    recognize_button = tk.Button(root, text=\"Identify Faces\", command=identify_faces, width=30, height=2)\n",
    "    recognize_button.pack(pady=20)\n",
    "\n",
    "    exit_button = tk.Button(root, text=\"Exit\", command=lambda: root.destroy(), width=30, height=2)\n",
    "    exit_button.pack(pady=20)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n",
      "Error sending data to Supabase: 'APIResponse[~_ReturnT]' object has no attribute 'get'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 142\u001b[0m\n\u001b[0;32m    139\u001b[0m     root\u001b[38;5;241m.\u001b[39mmainloop()\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 142\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 139\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    137\u001b[0m exit_button \u001b[38;5;241m=\u001b[39m tk\u001b[38;5;241m.\u001b[39mButton(root, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExit\u001b[39m\u001b[38;5;124m\"\u001b[39m, command\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: root\u001b[38;5;241m.\u001b[39mdestroy(), width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    138\u001b[0m exit_button\u001b[38;5;241m.\u001b[39mpack(pady\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m--> 139\u001b[0m \u001b[43mroot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\tkinter\\__init__.py:1429\u001b[0m, in \u001b[0;36mMisc.mainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog, messagebox\n",
    "import os\n",
    "import face_recognition\n",
    "from supabase import create_client, Client\n",
    "\n",
    "# Supabase configuration\n",
    "SUPABASE_URL = \"https://puhexttrixwbmbmokekb.supabase.co\"\n",
    "SUPABASE_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InB1aGV4dHRyaXh3Ym1ibW9rZWtiIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzM2NzAwMTcsImV4cCI6MjA0OTI0NjAxN30.3SLnBspTZB0XA97d5rjrTpkV_JsFEmwRB9eXeULBdYY\"\n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_API_KEY)\n",
    "\n",
    "# Directory to store captured faces\n",
    "DATA_DIR = \"faces_data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Function to send data to Supabase\n",
    "def send_to_supabase(name, access):\n",
    "    try:\n",
    "        response = supabase.table(\"faces\").insert({\"name\": name, \"access\": access}).execute()\n",
    "        if response.get(\"status_code\", 200) != 200:\n",
    "            raise Exception(response.get(\"message\", \"Failed to send data to Supabase\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending data to Supabase: {e}\")\n",
    "\n",
    "# Function to capture face and organize into folders\n",
    "def capture_face():\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter your name:\")\n",
    "    if not name:\n",
    "        messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "        return\n",
    "\n",
    "    user_dir = os.path.join(DATA_DIR, name)\n",
    "    os.makedirs(user_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    messagebox.showinfo(\"Info\", \"The system will automatically capture 50 frames of your face.\")\n",
    "\n",
    "    count = 0\n",
    "    while count < 50:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\").detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            face_path = os.path.join(user_dir, f\"{name}_{count}.jpg\")\n",
    "            cv2.imwrite(face_path, face)\n",
    "            count += 1\n",
    "            if count >= 50:\n",
    "                break\n",
    "\n",
    "        cv2.imshow(\"Capture Face\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    messagebox.showinfo(\"Success\", f\"Captured {count} frames for {name}.\")\n",
    "\n",
    "# Function to identify faces live\n",
    "def identify_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "    sent_names = set()  # Track sent names during the session\n",
    "\n",
    "    # Load known faces\n",
    "    for user_dir in os.listdir(DATA_DIR):\n",
    "        user_path = os.path.join(DATA_DIR, user_dir)\n",
    "        if os.path.isdir(user_path):\n",
    "            for file_name in os.listdir(user_path):\n",
    "                file_path = os.path.join(user_path, file_name)\n",
    "                img = face_recognition.load_image_file(file_path)\n",
    "                encoding = face_recognition.face_encodings(img)\n",
    "                if encoding:\n",
    "                    known_faces.append(encoding[0])\n",
    "                    known_names.append(user_dir)\n",
    "\n",
    "    if not known_faces:\n",
    "        messagebox.showerror(\"Error\", \"No faces found. Please capture some faces first.\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    messagebox.showinfo(\"Info\", \"Press 'q' to quit live recognition.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            matches = face_recognition.compare_faces(known_faces, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "            access = False\n",
    "\n",
    "            if True in matches:\n",
    "                first_match_index = matches.index(True)\n",
    "                name = known_names[first_match_index]\n",
    "                access = True\n",
    "\n",
    "            # Send to Supabase only if not already sent\n",
    "            if name != \"Unknown\" and name not in sent_names:\n",
    "                send_to_supabase(name, access)\n",
    "                sent_names.add(name)  # Mark as sent\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Live Face Recognition\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# GUI Application\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Face Recognition System\")\n",
    "\n",
    "    capture_button = tk.Button(root, text=\"Capture Face\", command=capture_face, width=30, height=2)\n",
    "    capture_button.pack(pady=20)\n",
    "\n",
    "    recognize_button = tk.Button(root, text=\"Identify Faces\", command=identify_faces, width=30, height=2)\n",
    "    recognize_button.pack(pady=20)\n",
    "\n",
    "    exit_button = tk.Button(root, text=\"Exit\", command=lambda: root.destroy(), width=30, height=2)\n",
    "    exit_button.pack(pady=20)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n",
      "Error: module 'deepface.modules.modeling' has no attribute 'build_model'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 110\u001b[0m\n\u001b[0;32m    107\u001b[0m     root\u001b[38;5;241m.\u001b[39mmainloop()\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 110\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 107\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    104\u001b[0m exit_button \u001b[38;5;241m=\u001b[39m tk\u001b[38;5;241m.\u001b[39mButton(root, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExit\u001b[39m\u001b[38;5;124m\"\u001b[39m, command\u001b[38;5;241m=\u001b[39mroot\u001b[38;5;241m.\u001b[39mdestroy, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    105\u001b[0m exit_button\u001b[38;5;241m.\u001b[39mpack(pady\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m--> 107\u001b[0m \u001b[43mroot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\tkinter\\__init__.py:1429\u001b[0m, in \u001b[0;36mMisc.mainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from deepface import DeepFace\n",
    "from tkinter import simpledialog, messagebox, Tk\n",
    "import tkinter as tk\n",
    "import numpy as np\n",
    "\n",
    "# Directory to store face embeddings\n",
    "DATA_DIR = \"face_embeddings\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Function to capture and save face embeddings\n",
    "def capture_face_embeddings():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter your name:\")\n",
    "    if not name:\n",
    "        messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "        return\n",
    "\n",
    "    user_path = os.path.join(DATA_DIR, f\"{name}.npy\")\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    messagebox.showinfo(\"Info\", \"Capturing your face. Look at the camera.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        cv2.imshow(\"Capture Face\", frame)\n",
    "\n",
    "        # Press 'c' to capture and save embedding\n",
    "        if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "            try:\n",
    "                # Detect and analyze face\n",
    "                result = DeepFace.represent(frame, model_name=\"Facenet\", enforce_detection=True)\n",
    "                np.save(user_path, result[0][\"embedding\"])\n",
    "                messagebox.showinfo(\"Success\", f\"Face embedding saved for {name}.\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Failed to process face: {e}\")\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to verify face in real-time\n",
    "def real_time_verification():\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    messagebox.showinfo(\"Info\", \"Press 'v' to verify or 'q' to quit.\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        cv2.imshow(\"Real-Time Verification\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('v'):\n",
    "            try:\n",
    "                # Detect and analyze face\n",
    "                input_embedding = DeepFace.represent(frame, model_name=\"Facenet\", enforce_detection=True)[0][\"embedding\"]\n",
    "\n",
    "                # Load stored embeddings and compare\n",
    "                results = []\n",
    "                for file in os.listdir(DATA_DIR):\n",
    "                    stored_embedding = np.load(os.path.join(DATA_DIR, file))\n",
    "                    distance = np.linalg.norm(np.array(input_embedding) - np.array(stored_embedding))\n",
    "                    results.append((file, distance))\n",
    "\n",
    "                # Find the best match\n",
    "                results.sort(key=lambda x: x[1])  # Sort by distance\n",
    "                best_match, best_distance = results[0]\n",
    "                print(f\"Best Match: {best_match}, Distance: {best_distance}\")\n",
    "\n",
    "                if best_distance < 0.6:  # Threshold for matching\n",
    "                    print(f\"Access Granted: {best_match}\")\n",
    "                    cv2.putText(frame, f\"Access Granted: {best_match}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                else:\n",
    "                    print(\"Access Denied\")\n",
    "                    cv2.putText(frame, \"Access Denied\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# GUI Application\n",
    "def main():\n",
    "    root = Tk()\n",
    "    root.title(\"Face Verification System\")\n",
    "\n",
    "    capture_button = tk.Button(root, text=\"Capture Face Embeddings\", command=capture_face_embeddings, width=30, height=2)\n",
    "    capture_button.pack(pady=20)\n",
    "\n",
    "    verify_button = tk.Button(root, text=\"Real-Time Verification\", command=real_time_verification, width=30, height=2)\n",
    "    verify_button.pack(pady=20)\n",
    "\n",
    "    exit_button = tk.Button(root, text=\"Exit\", command=root.destroy, width=30, height=2)\n",
    "    exit_button.pack(pady=20)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to verify face in real-time with name display\n",
    "def real_time_verification():\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    messagebox.showinfo(\"Info\", \"Press 'v' to verify or 'q' to quit.\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        cv2.imshow(\"Real-Time Verification\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('v'):\n",
    "            try:\n",
    "                # Detect and analyze face\n",
    "                input_embedding = DeepFace.represent(frame, model_name=\"Facenet\", enforce_detection=True)[0][\"embedding\"]\n",
    "\n",
    "                # Load stored embeddings and compare\n",
    "                results = []\n",
    "                for file in os.listdir(DATA_DIR):\n",
    "                    stored_embedding = np.load(os.path.join(DATA_DIR, file))\n",
    "                    distance = np.linalg.norm(np.array(input_embedding) - np.array(stored_embedding))\n",
    "                    results.append((file, distance))\n",
    "\n",
    "                # Find the best match\n",
    "                results.sort(key=lambda x: x[1])  # Sort by distance\n",
    "                best_match, best_distance = results[0]\n",
    "                user_name = best_match.split('.')[0]  # Extract user name from file name\n",
    "                print(f\"Best Match: {user_name}, Distance: {best_distance}\")\n",
    "\n",
    "                if best_distance < 0.6:  # Threshold for matching\n",
    "                    print(f\"Access Granted: {user_name}\")\n",
    "                    cv2.putText(frame, f\"Access Granted: {user_name}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                else:\n",
    "                    print(\"Access Denied\")\n",
    "                    cv2.putText(frame, \"Access Denied\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "                # Display updated frame with text\n",
    "                cv2.imshow(\"Real-Time Verification\", frame)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to verify face in real-time with name display\n",
    "def real_time_verification():\n",
    "    cap = cv2.VideoCapture(2)  # Open video capture\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", \"Press 'v' to verify or 'q' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Clone the frame for updates\n",
    "        display_frame = frame.copy()\n",
    "\n",
    "        # Verification logic when 'v' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('v'):\n",
    "            try:\n",
    "                # Generate the embedding for the current frame\n",
    "                input_embedding = DeepFace.represent(frame, model_name=\"Facenet\", enforce_detection=True)[0][\"embedding\"]\n",
    "\n",
    "                # Load stored embeddings and calculate distances\n",
    "                results = []\n",
    "                for file in os.listdir(DATA_DIR):\n",
    "                    stored_embedding = np.load(os.path.join(DATA_DIR, file))\n",
    "                    distance = np.linalg.norm(np.array(input_embedding) - np.array(stored_embedding))\n",
    "                    results.append((file, distance))\n",
    "\n",
    "                # Sort results to find the closest match\n",
    "                results.sort(key=lambda x: x[1])\n",
    "                best_match, best_distance = results[0]\n",
    "                user_name = best_match.split('.')[0]  # Extract user name from file name\n",
    "\n",
    "                # Display verification result on the frame\n",
    "                if best_distance < 0.6:  # Matching threshold\n",
    "                    print(f\"Verified: {user_name}, Distance: {best_distance}\")\n",
    "                    cv2.putText(display_frame, f\"Verified: {user_name}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                else:\n",
    "                    print(\"Unknown Face Detected\")\n",
    "                    cv2.putText(display_frame, \"Unknown\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error during verification: {e}\")\n",
    "                cv2.putText(display_frame, \"Error Detecting Face\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Display the updated frame\n",
    "        cv2.imshow(\"Real-Time Verification\", display_frame)\n",
    "\n",
    "        # Quit the feed on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture and close the window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFaceid\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mphotos\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124monaldo1.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m rgb_img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m img_encoding \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_encodings(rgb_img)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m img2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages/Messi.webp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"Faceid\\photos\\ronaldo1.jpg\")\n",
    "rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_encoding = face_recognition.face_encodings(rgb_img)[0]\n",
    "img2 = cv2.imread(\"images/Messi.webp\")\n",
    "rgb_img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "img_encoding2 = face_recognition.face_encodings(rgb_img2)[0]\n",
    "result = face_recognition.compare_faces([img_encoding], img_encoding2)\n",
    "print(\"Result: \", result)\n",
    "# Encode faces from a folder\n",
    "sfr = SimpleFacerec()\n",
    "sfr.load_encoding_images(\"images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from simple_facerec import SimpleFacerec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement simple_facerec (from versions: none)\n",
      "ERROR: No matching distribution found for simple_facerec\n"
     ]
    }
   ],
   "source": [
    "!pip3 install simple_facerec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessi1.webp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m rgb_img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m img_encoding \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_encodings(rgb_img)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"Messi1.webp\")\n",
    "rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_encoding = face_recognition.face_encodings(rgb_img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 encoding images found.\n",
      "Encoding images loaded\n",
      "1 encoding images found.\n",
      "Encoding images loaded\n",
      "2 encoding images found.\n",
      "Encoding images loaded\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 133\u001b[0m\n\u001b[0;32m    129\u001b[0m     root\u001b[38;5;241m.\u001b[39mmainloop()\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 133\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 129\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    126\u001b[0m exit_button\u001b[38;5;241m.\u001b[39mpack(pady\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# Run the GUI event loop\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m \u001b[43mroot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\tkinter\\__init__.py:1429\u001b[0m, in \u001b[0;36mMisc.mainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from simple_facerec import SimpleFacerec\n",
    "import os\n",
    "from tkinter import Tk, Button, messagebox, simpledialog\n",
    "\n",
    "# Initialize Face Recognition\n",
    "sfr = SimpleFacerec()\n",
    "\n",
    "# Directory to store face encodings\n",
    "ENCODINGS_DIR = \"face_encodings/\"\n",
    "os.makedirs(ENCODINGS_DIR, exist_ok=True)\n",
    "\n",
    "# Load existing encodings\n",
    "sfr.load_encoding_images(ENCODINGS_DIR)\n",
    "\n",
    "\n",
    "# Function to save a new user's face encoding\n",
    "def save_user():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter the name of the new user:\")\n",
    "    if not name:\n",
    "        messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", \"Look at the camera. Press 'c' to capture your photo.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Display live feed\n",
    "        cv2.imshow(\"Save User - Capture Mode\", frame)\n",
    "\n",
    "        # Press 'c' to capture and save the user's photo\n",
    "        if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "            # Save the captured photo to the encodings directory\n",
    "            file_path = os.path.join(ENCODINGS_DIR, f\"{name}.jpg\")\n",
    "            cv2.imwrite(file_path, frame)\n",
    "            messagebox.showinfo(\"Success\", f\"User's photo saved as {file_path}\")\n",
    "            break\n",
    "\n",
    "        # Press 'q' to quit without saving\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Re-load encodings after saving\n",
    "    sfr.load_encoding_images(ENCODINGS_DIR)\n",
    "    messagebox.showinfo(\"Info\", \"New user encoded and added to the system.\")\n",
    "\n",
    "\n",
    "# Function for live face identification\n",
    "def live_identification():\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", \"Press 'q' to quit live identification.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Detect Faces\n",
    "        face_locations, face_names = sfr.detect_known_faces(frame)\n",
    "        for face_loc, name in zip(face_locations, face_names):\n",
    "            y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n",
    "\n",
    "            # Draw rectangle around the face\n",
    "            color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "            # Add name label\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                name,\n",
    "                (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_DUPLEX,\n",
    "                1,\n",
    "                color,\n",
    "                2,\n",
    "            )\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Live Identification\", frame)\n",
    "\n",
    "        # Quit on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# GUI Application\n",
    "def main():\n",
    "    # Create a GUI window\n",
    "    root = Tk()\n",
    "    root.title(\"Face Recognition System\")\n",
    "\n",
    "    # Buttons for saving users and live identification\n",
    "    save_user_button = Button(\n",
    "        root, text=\"Save New User\", command=save_user, width=30, height=2\n",
    "    )\n",
    "    save_user_button.pack(pady=20)\n",
    "\n",
    "    live_identification_button = Button(\n",
    "        root, text=\"Live Identification\", command=live_identification, width=30, height=2\n",
    "    )\n",
    "    live_identification_button.pack(pady=20)\n",
    "\n",
    "    exit_button = Button(root, text=\"Exit\", command=root.destroy, width=30, height=2)\n",
    "    exit_button.pack(pady=20)\n",
    "\n",
    "    # Run the GUI event loop\n",
    "    root.mainloop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 encoding images found.\n",
      "Encoding images loaded\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from simple_facerec import SimpleFacerec\n",
    "import os\n",
    "from tkinter import Tk, Button, messagebox, simpledialog\n",
    "\n",
    "# Initialize Face Recognition\n",
    "sfr = SimpleFacerec()\n",
    "\n",
    "# Directory to store face encodings\n",
    "ENCODINGS_DIR = \"face_encodings/\"\n",
    "os.makedirs(ENCODINGS_DIR, exist_ok=True)\n",
    "\n",
    "# Load existing encodings\n",
    "sfr.load_encoding_images(ENCODINGS_DIR)\n",
    "\n",
    "\n",
    "# Function to save a new user's face encoding\n",
    "def save_user():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter the name of the new user:\")\n",
    "    if not name:\n",
    "        messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", \"Look at the camera. Press 'c' to capture your photo.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Display live feed\n",
    "        cv2.imshow(\"Save User - Capture Mode\", frame)\n",
    "\n",
    "        # Press 'c' to capture and save the user's photo\n",
    "        if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "            # Save the captured photo to the encodings directory\n",
    "            file_path = os.path.join(ENCODINGS_DIR, f\"{name}.jpg\")\n",
    "            cv2.imwrite(file_path, frame)\n",
    "            messagebox.showinfo(\"Success\", f\"User's photo saved as {file_path}\")\n",
    "            break\n",
    "\n",
    "        # Press 'q' to quit without saving\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Re-load encodings after saving\n",
    "    sfr.load_encoding_images(ENCODINGS_DIR)\n",
    "    messagebox.showinfo(\"Info\", \"New user encoded and added to the system.\")\n",
    "\n",
    "\n",
    "# Function for live face identification\n",
    "def live_identification():\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", \"Press 'q' to quit live identification.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Detect Faces\n",
    "        face_locations, face_names = sfr.detect_known_faces(frame)\n",
    "        for face_loc, name in zip(face_locations, face_names):\n",
    "            y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n",
    "\n",
    "            # Draw rectangle around the face\n",
    "            color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "            # Add name label\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                name,\n",
    "                (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_DUPLEX,\n",
    "                1,\n",
    "                color,\n",
    "                2,\n",
    "            )\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Live Identification\", frame)\n",
    "\n",
    "        # Quit on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# GUI Application\n",
    "def main():\n",
    "    import os\n",
    "\n",
    "    # Create a GUI window\n",
    "    root = Tk()\n",
    "    root.title(\"Face Recognition System\")\n",
    "\n",
    "    # Buttons for saving users and live identification\n",
    "    save_user_button = Button(\n",
    "        root, text=\"Save New User\", command=save_user, width=30, height=2\n",
    "    )\n",
    "    save_user_button.pack(pady=20)\n",
    "\n",
    "    live_identification_button = Button(\n",
    "        root, text=\"Live Identification\", command=live_identification, width=30, height=2\n",
    "    )\n",
    "    live_identification_button.pack(pady=20)\n",
    "\n",
    "    # Exit button to close the entire application\n",
    "    def exit_application():\n",
    "        root.destroy()  # Close the Tkinter window\n",
    "        os._exit(0)  # Terminate the Python program completely\n",
    "\n",
    "    exit_button = Button(root, text=\"Exit\", command=exit_application, width=30, height=2)\n",
    "    exit_button.pack(pady=20)\n",
    "\n",
    "    # Run the GUI event loop\n",
    "    root.mainloop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured frame 1 for ali\n",
      "Captured frame 2 for ali\n",
      "Captured frame 3 for ali\n",
      "Captured frame 4 for ali\n",
      "Captured frame 5 for ali\n",
      "Captured frame 1 for ziad\n",
      "Captured frame 2 for ziad\n",
      "Captured frame 3 for ziad\n",
      "Captured frame 4 for ziad\n",
      "Captured frame 5 for ziad\n",
      "Captured frame 1 for ziad\n",
      "Captured frame 2 for ziad\n",
      "Captured frame 3 for ziad\n",
      "Captured frame 4 for ziad\n",
      "Captured frame 5 for ziad\n",
      "Captured frame 1 for ziad\n",
      "Captured frame 2 for ziad\n",
      "Captured frame 3 for ziad\n",
      "Captured frame 4 for ziad\n",
      "Captured frame 5 for ziad\n",
      "Captured frame 1 for hussien\n",
      "Captured frame 2 for hussien\n",
      "Captured frame 3 for hussien\n",
      "Captured frame 4 for hussien\n",
      "Captured frame 5 for hussien\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "from tkinter import Tk, Button, messagebox, simpledialog\n",
    "import numpy as np\n",
    "\n",
    "# Directory to store face encodings\n",
    "ENCODINGS_DIR = \"face_encodings/\"\n",
    "os.makedirs(ENCODINGS_DIR, exist_ok=True)\n",
    "\n",
    "# Load known face encodings and names\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "def load_encodings():\n",
    "    global known_face_encodings, known_face_names\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    for user_folder in os.listdir(ENCODINGS_DIR):\n",
    "        user_path = os.path.join(ENCODINGS_DIR, user_folder)\n",
    "        if os.path.isdir(user_path):\n",
    "            for file in os.listdir(user_path):\n",
    "                file_path = os.path.join(user_path, file)\n",
    "                image = face_recognition.load_image_file(file_path)\n",
    "                encodings = face_recognition.face_encodings(image)\n",
    "                if encodings:\n",
    "                    known_face_encodings.append(encodings[0])\n",
    "                    known_face_names.append(user_folder)\n",
    "\n",
    "\n",
    "# Function to save a new user's face encoding\n",
    "def save_user():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter the name of the new user:\")\n",
    "    if not name:\n",
    "        messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "        return\n",
    "\n",
    "    user_dir = os.path.join(ENCODINGS_DIR, name)\n",
    "    os.makedirs(user_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", f\"Capturing 5 frames for {name}. Look at the camera.\")\n",
    "\n",
    "    count = 0\n",
    "    while count < 5:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Display live feed\n",
    "        cv2.imshow(\"Save User - Capture Mode\", frame)\n",
    "\n",
    "        # Capture and save the frame\n",
    "        file_path = os.path.join(user_dir, f\"{name}_{count}.jpg\")\n",
    "        cv2.imwrite(file_path, frame)\n",
    "        count += 1\n",
    "        print(f\"Captured frame {count} for {name}\")\n",
    "\n",
    "        # Wait for 500ms before capturing the next frame\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Reload encodings after saving\n",
    "    load_encodings()\n",
    "    messagebox.showinfo(\"Info\", f\"Frames captured and {name} added to the system.\")\n",
    "\n",
    "\n",
    "# Function for live face identification\n",
    "def live_identification():\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", \"Press 'q' to quit live identification.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert frame to RGB (face_recognition expects RGB images)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect faces and their encodings\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # Compare with known faces\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "\n",
    "            # Identify the best match\n",
    "            name = \"Unknown\"\n",
    "            accuracy = 0\n",
    "            if matches:\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "                    accuracy = 100 - (face_distances[best_match_index] * 100)\n",
    "\n",
    "            # Check accuracy threshold\n",
    "            if accuracy < 65:\n",
    "                name = \"Unknown\"\n",
    "\n",
    "            # Display the name and accuracy\n",
    "            display_name = f\"{name} ({accuracy:.2f}%)\" if name != \"Unknown\" else \"Unknown\"\n",
    "            color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "\n",
    "            # Draw rectangle around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "\n",
    "            # Add name label\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                display_name,\n",
    "                (left, top - 10),\n",
    "                cv2.FONT_HERSHEY_DUPLEX,\n",
    "                0.8,\n",
    "                color,\n",
    "                2,\n",
    "            )\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Live Identification\", frame)\n",
    "\n",
    "        # Quit on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# GUI Application\n",
    "def main():\n",
    "    # Load encodings initially\n",
    "    load_encodings()\n",
    "\n",
    "    # Create a GUI window\n",
    "    root = Tk()\n",
    "    root.title(\"Face Recognition System\")\n",
    "\n",
    "    # Buttons for saving users and live identification\n",
    "    save_user_button = Button(\n",
    "        root, text=\"Save New User\", command=save_user, width=30, height=2\n",
    "    )\n",
    "    save_user_button.pack(pady=20)\n",
    "\n",
    "    live_identification_button = Button(\n",
    "        root, text=\"Live Identification\", command=live_identification, width=30, height=2\n",
    "    )\n",
    "    live_identification_button.pack(pady=20)\n",
    "\n",
    "    # Exit button to close the entire application\n",
    "    def exit_application():\n",
    "        root.destroy()  # Close the Tkinter window\n",
    "        os._exit(0)  # Terminate the Python program completely\n",
    "\n",
    "    exit_button = Button(root, text=\"Exit\", command=exit_application, width=30, height=2)\n",
    "    exit_button.pack(pady=20)\n",
    "\n",
    "    # Run the GUI event loop\n",
    "    root.mainloop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured frame 1 for ali\n",
      "Captured frame 2 for ali\n",
      "Captured frame 3 for ali\n",
      "Captured frame 4 for ali\n",
      "Captured frame 5 for ali\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "from tkinter import Tk, Button, messagebox, simpledialog\n",
    "import numpy as np\n",
    "\n",
    "# Directory to store face encodings\n",
    "ENCODINGS_DIR = \"face_encodings/\"\n",
    "os.makedirs(ENCODINGS_DIR, exist_ok=True)\n",
    "\n",
    "# Load known face encodings and names\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "def load_encodings():\n",
    "    global known_face_encodings, known_face_names\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    for user_folder in os.listdir(ENCODINGS_DIR):\n",
    "        user_path = os.path.join(ENCODINGS_DIR, user_folder)\n",
    "        if os.path.isdir(user_path):\n",
    "            for file in os.listdir(user_path):\n",
    "                file_path = os.path.join(user_path, file)\n",
    "                image = face_recognition.load_image_file(file_path)\n",
    "                encodings = face_recognition.face_encodings(image)\n",
    "                if encodings:\n",
    "                    known_face_encodings.append(encodings[0])\n",
    "                    known_face_names.append(user_folder)\n",
    "\n",
    "\n",
    "# Function to save a new user's face encoding\n",
    "def save_user():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter the name of the new user:\")\n",
    "    if not name:\n",
    "        messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "        return\n",
    "\n",
    "    user_dir = os.path.join(ENCODINGS_DIR, name)\n",
    "    os.makedirs(user_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", f\"Capturing 5 frames for {name}. Look at the camera.\")\n",
    "\n",
    "    count = 0\n",
    "    while count < 5:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Display live feed\n",
    "        cv2.imshow(\"Save User - Capture Mode\", frame)\n",
    "\n",
    "        # Capture and save the frame\n",
    "        file_path = os.path.join(user_dir, f\"{name}_{count}.jpg\")\n",
    "        cv2.imwrite(file_path, frame)\n",
    "        count += 1\n",
    "        print(f\"Captured frame {count} for {name}\")\n",
    "\n",
    "        # Wait for 500ms before capturing the next frame\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Reload encodings after saving\n",
    "    load_encodings()\n",
    "    messagebox.showinfo(\"Info\", f\"Frames captured and {name} added to the system.\")\n",
    "\n",
    "\n",
    "# Function for live face identification\n",
    "def live_identification():\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", \"Press 'q' to quit live identification.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert frame to RGB (face_recognition expects RGB images)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect faces and their encodings\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # Compare with known faces\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "\n",
    "            # Identify the best match\n",
    "            name = \"Unknown\"\n",
    "            accuracy = 0\n",
    "            if matches:\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "                    accuracy = 100 - (face_distances[best_match_index] * 100)\n",
    "\n",
    "            # Check accuracy threshold\n",
    "            if accuracy < 75:\n",
    "                name = \"Unknown\"\n",
    "\n",
    "            # Display the name and accuracy\n",
    "            display_name = f\"{name} ({accuracy:.2f}%)\" if name != \"Unknown\" else \"Unknown\"\n",
    "            color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "\n",
    "            # Draw rectangle around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "\n",
    "            # Add name label\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                display_name,\n",
    "                (left, top - 10),\n",
    "                cv2.FONT_HERSHEY_DUPLEX,\n",
    "                0.8,\n",
    "                color,\n",
    "                2,\n",
    "            )\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Live Identification\", frame)\n",
    "\n",
    "        # Quit on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# GUI Application\n",
    "def main():\n",
    "    # Load encodings initially\n",
    "    load_encodings()\n",
    "\n",
    "    # Create a GUI window\n",
    "    root = Tk()\n",
    "    root.title(\"Face Recognition System\")\n",
    "\n",
    "    # Buttons for saving users and live identification\n",
    "    save_user_button = Button(\n",
    "        root, text=\"Save New User\", command=save_user, width=30, height=2\n",
    "    )\n",
    "    save_user_button.pack(pady=20)\n",
    "\n",
    "    live_identification_button = Button(\n",
    "        root, text=\"Live Identification\", command=live_identification, width=30, height=2\n",
    "    )\n",
    "    live_identification_button.pack(pady=20)\n",
    "\n",
    "    # Exit button to close the entire application\n",
    "    def exit_application():\n",
    "        root.destroy()  # Close the Tkinter window\n",
    "        import sys\n",
    "        sys.exit(0)  # Gracefully terminate the program\n",
    "\n",
    "    exit_button = Button(root, text=\"Exit\", command=exit_application, width=30, height=2)\n",
    "    exit_button.pack(pady=20)\n",
    "\n",
    "    # Run the GUI event loop\n",
    "    root.mainloop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured frame 1 for ali\n",
      "Captured frame 2 for ali\n",
      "Captured frame 3 for ali\n",
      "Captured frame 4 for ali\n",
      "Captured frame 5 for ali\n",
      "Captured frame 6 for ali\n",
      "Captured frame 7 for ali\n",
      "Captured frame 8 for ali\n",
      "Captured frame 9 for ali\n",
      "Captured frame 10 for ali\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "from tkinter import Tk, Button, messagebox, simpledialog\n",
    "import numpy as np\n",
    "\n",
    "# Directory to store face encodings\n",
    "ENCODINGS_DIR = \"face_encodings/\"\n",
    "os.makedirs(ENCODINGS_DIR, exist_ok=True)\n",
    "\n",
    "# Load known face encodings and names\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "def load_encodings():\n",
    "    global known_face_encodings, known_face_names\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    for user_folder in os.listdir(ENCODINGS_DIR):\n",
    "        user_path = os.path.join(ENCODINGS_DIR, user_folder)\n",
    "        if os.path.isdir(user_path):\n",
    "            for file in os.listdir(user_path):\n",
    "                file_path = os.path.join(user_path, file)\n",
    "                image = face_recognition.load_image_file(file_path)\n",
    "                encodings = face_recognition.face_encodings(image)\n",
    "                if encodings:\n",
    "                    known_face_encodings.append(encodings[0])\n",
    "                    known_face_names.append(user_folder)\n",
    "\n",
    "\n",
    "# Function to save a new user's face encoding\n",
    "def save_user():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter the name of the new user:\")\n",
    "    if not name:\n",
    "        messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "        return\n",
    "\n",
    "    user_dir = os.path.join(ENCODINGS_DIR, name)\n",
    "    os.makedirs(user_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", f\"Capturing 10 frames for {name}. Look at the camera.\")\n",
    "\n",
    "    count = 0\n",
    "    while count < 10:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Display live feed\n",
    "        cv2.imshow(\"Save User - Capture Mode\", frame)\n",
    "\n",
    "        # Capture and save the frame\n",
    "        file_path = os.path.join(user_dir, f\"{name}_{count}.jpg\")\n",
    "        cv2.imwrite(file_path, frame)\n",
    "        count += 1\n",
    "        print(f\"Captured frame {count} for {name}\")\n",
    "\n",
    "        # Wait for 500ms before capturing the next frame\n",
    "        cv2.waitKey(1000)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Reload encodings after saving\n",
    "    load_encodings()\n",
    "    messagebox.showinfo(\"Info\", f\"Frames captured and {name} added to the system.\")\n",
    "\n",
    "\n",
    "# Function for live face identification\n",
    "def live_identification():\n",
    "    cap = cv2.VideoCapture(1)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", \"Press 'q' to quit live identification.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert frame to RGB (face_recognition expects RGB images)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect faces and their encodings\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # Compare with known faces\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "\n",
    "            # Identify the best match\n",
    "            name = \"Unknown\"\n",
    "            accuracy = 0\n",
    "            if matches:\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "                    accuracy = 100 - (face_distances[best_match_index] * 100)\n",
    "\n",
    "            # Check accuracy threshold\n",
    "            if accuracy < 65:\n",
    "                name = \"Unknown\"\n",
    "\n",
    "            # Display the name and accuracy\n",
    "            display_name = f\"{name} ({accuracy:.2f}%)\" if name != \"Unknown\" else \"Unknown\"\n",
    "            color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "\n",
    "            # Draw rectangle around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "\n",
    "            # Add name label\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                display_name,\n",
    "                (left, top - 10),\n",
    "                cv2.FONT_HERSHEY_DUPLEX,\n",
    "                0.8,\n",
    "                color,\n",
    "                2,\n",
    "            )\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Live Identification\", frame)\n",
    "\n",
    "        # Quit on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# GUI Application\n",
    "def main():\n",
    "    # Load encodings initially\n",
    "    load_encodings()\n",
    "\n",
    "    # Create a GUI window\n",
    "    root = Tk()\n",
    "    root.title(\"Face Recognition System\")\n",
    "\n",
    "    # Buttons for saving users and live identification\n",
    "    save_user_button = Button(\n",
    "        root, text=\"Save New User\", command=save_user, width=30, height=2\n",
    "    )\n",
    "    save_user_button.pack(pady=20)\n",
    "\n",
    "    live_identification_button = Button(\n",
    "        root, text=\"Live Identification\", command=live_identification, width=30, height=2\n",
    "    )\n",
    "    live_identification_button.pack(pady=20)\n",
    "\n",
    "    # Exit button to close the entire application\n",
    "    def exit_application():\n",
    "        root.destroy()  # Close the Tkinter window\n",
    "        os._exit(0)  # Terminate the Python program completely\n",
    "\n",
    "    exit_button = Button(root, text=\"Exit\", command=exit_application, width=30, height=2)\n",
    "    exit_button.pack(pady=20)\n",
    "\n",
    "    # Run the GUI event loop\n",
    "    root.mainloop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sent to Supabase successfully: [{'id': 'd7e9c6c5-540c-42b0-892d-a333bd320248', 'name': 'Unknown', 'access': False}]\n",
      "Data sent to Supabase successfully: [{'id': '0b0bb9d1-082c-4ca2-a417-1686fe447bda', 'name': 'Unknown', 'access': False}]\n",
      "Data sent to Supabase successfully: [{'id': 'c895e38d-f8f5-45a7-8f66-6fece2be75c0', 'name': 'ali', 'access': True}]\n",
      "Data sent to Supabase successfully: [{'id': '080518a2-e07e-420a-80e3-9ce39c040dc1', 'name': 'ali', 'access': True}]\n",
      "Data sent to Supabase successfully: [{'id': 'd3c16218-e5f2-43bd-8792-18df4e34c5a0', 'name': 'ali', 'access': True}]\n",
      "Data sent to Supabase successfully: [{'id': '9ad8470c-74df-4b55-bb0e-44a5bb0b8bad', 'name': 'ali', 'access': True}]\n",
      "Data sent to Supabase successfully: [{'id': '51a9f691-a9dc-4da1-b724-4fbb23e932a0', 'name': 'ali', 'access': True}]\n",
      "Data sent to Supabase successfully: [{'id': 'b5b384fa-9569-439f-b1e6-d5e5458d1800', 'name': 'ali', 'access': True}]\n",
      "Data sent to Supabase successfully: [{'id': '3a65dedd-00b3-40c4-9c5e-0708c69e4387', 'name': 'Unknown', 'access': False}]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "from tkinter import Tk, Button, messagebox, simpledialog\n",
    "import numpy as np\n",
    "from supabase import create_client, Client\n",
    "\n",
    "# Supabase configuration\n",
    "SUPABASE_URL = \"https://puhexttrixwbmbmokekb.supabase.co\"\n",
    "SUPABASE_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InB1aGV4dHRyaXh3Ym1ibW9rZWtiIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzM2NzAwMTcsImV4cCI6MjA0OTI0NjAxN30.3SLnBspTZB0XA97d5rjrTpkV_JsFEmwRB9eXeULBdYY\"\n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_API_KEY)\n",
    "\n",
    "# Directory to store face encodings\n",
    "ENCODINGS_DIR = \"face_encodings/\"\n",
    "os.makedirs(ENCODINGS_DIR, exist_ok=True)\n",
    "\n",
    "# Load known face encodings and names\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "def load_encodings():\n",
    "    global known_face_encodings, known_face_names\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    for user_folder in os.listdir(ENCODINGS_DIR):\n",
    "        user_path = os.path.join(ENCODINGS_DIR, user_folder)\n",
    "        if os.path.isdir(user_path):\n",
    "            for file in os.listdir(user_path):\n",
    "                file_path = os.path.join(user_path, file)\n",
    "                image = face_recognition.load_image_file(file_path)\n",
    "                encodings = face_recognition.face_encodings(image)\n",
    "                if encodings:\n",
    "                    known_face_encodings.append(encodings[0])\n",
    "                    known_face_names.append(user_folder)\n",
    "\n",
    "# Function to send data to Supabase\n",
    "def send_to_supabase(name, access):\n",
    "    try:\n",
    "        response = supabase.table(\"faces\").insert({\"name\": name, \"access\": access}).execute()\n",
    "        \n",
    "        # Inspect the response\n",
    "        if not response.data:\n",
    "            raise Exception(\"Failed to send data to Supabase. Response returned no data.\")\n",
    "        \n",
    "        print(f\"Data sent to Supabase successfully: {response.data}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending data to Supabase: {e}\")\n",
    "\n",
    "# Function to save a new user's face encoding\n",
    "def save_user():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter the name of the new user:\")\n",
    "    if not name:\n",
    "        messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "        return\n",
    "\n",
    "    user_dir = os.path.join(ENCODINGS_DIR, name)\n",
    "    os.makedirs(user_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", f\"Capturing 10 frames for {name}. Look at the camera.\")\n",
    "\n",
    "    count = 0\n",
    "    while count < 10:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Display live feed\n",
    "        cv2.imshow(\"Save User - Capture Mode\", frame)\n",
    "\n",
    "        # Capture and save the frame\n",
    "        file_path = os.path.join(user_dir, f\"{name}_{count}.jpg\")\n",
    "        cv2.imwrite(file_path, frame)\n",
    "        count += 1\n",
    "        print(f\"Captured frame {count} for {name}\")\n",
    "\n",
    "        # Wait for 500ms before capturing the next frame\n",
    "        cv2.waitKey(1000)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Reload encodings after saving\n",
    "    load_encodings()\n",
    "    messagebox.showinfo(\"Info\", f\"Frames captured and {name} added to the system.\")\n",
    "\n",
    "# Function for live face identification\n",
    "def live_identification():\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", \"Press 'q' to quit live identification.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert frame to RGB (face_recognition expects RGB images)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect faces and their encodings\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # Default to Unknown with access set to False\n",
    "            name = \"Unknown\"\n",
    "            access = False\n",
    "            accuracy = 0\n",
    "\n",
    "            # Compare with known faces\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "\n",
    "            if matches:\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "                    access = True\n",
    "                    accuracy = 100 - (face_distances[best_match_index] * 100)\n",
    "\n",
    "            # Check accuracy threshold\n",
    "            if accuracy < 65:\n",
    "                name = \"Unknown\"\n",
    "                access = False\n",
    "\n",
    "            # Send data to Supabase for each detected face\n",
    "            send_to_supabase(name, access)\n",
    "\n",
    "            # Display the name and accuracy\n",
    "            display_name = f\"{name} ({accuracy:.2f}%)\" if name != \"Unknown\" else \"Unknown\"\n",
    "            color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "\n",
    "            # Draw rectangle around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "\n",
    "            # Add name label\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                display_name,\n",
    "                (left, top - 10),\n",
    "                cv2.FONT_HERSHEY_DUPLEX,\n",
    "                0.8,\n",
    "                color,\n",
    "                2,\n",
    "            )\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Live Identification\", frame)\n",
    "\n",
    "        # Quit on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# GUI Application\n",
    "def main():\n",
    "    # Load encodings initially\n",
    "    load_encodings()\n",
    "\n",
    "    # Create a GUI window\n",
    "    root = Tk()\n",
    "    root.title(\"Face Recognition System\")\n",
    "\n",
    "    # Buttons for saving users and live identification\n",
    "    save_user_button = Button(\n",
    "        root, text=\"Save New User\", command=save_user, width=30, height=2\n",
    "    )\n",
    "    save_user_button.pack(pady=20)\n",
    "\n",
    "    live_identification_button = Button(\n",
    "        root, text=\"Live Identification\", command=live_identification, width=30, height=2\n",
    "    )\n",
    "    live_identification_button.pack(pady=20)\n",
    "\n",
    "    # Exit button to close the entire application\n",
    "    def exit_application():\n",
    "        root.destroy()  # Close the Tkinter window\n",
    "        os._exit(0)  # Terminate the Python program completely\n",
    "\n",
    "    exit_button = Button(root, text=\"Exit\", command=exit_application, width=30, height=2)\n",
    "    exit_button.pack(pady=20)\n",
    "\n",
    "    # Run the GUI event loop\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access for ali updated to True in Supabase.\n",
      "Access for ali updated to True in Supabase.\n",
      "Access for ali updated to True in Supabase.\n",
      "Access for ali updated to True in Supabase.\n",
      "Access for ali updated to True in Supabase.\n",
      "Access for ali updated to False in Supabase.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "from tkinter import Tk, Button, messagebox, simpledialog\n",
    "import numpy as np\n",
    "from supabase import create_client, Client\n",
    "\n",
    "# Supabase configuration\n",
    "SUPABASE_URL = \"https://puhexttrixwbmbmokekb.supabase.co\"\n",
    "SUPABASE_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InB1aGV4dHRyaXh3Ym1ibW9rZWtiIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzM2NzAwMTcsImV4cCI6MjA0OTI0NjAxN30.3SLnBspTZB0XA97d5rjrTpkV_JsFEmwRB9eXeULBdYY\"\n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_API_KEY)\n",
    "\n",
    "# Directory to store face encodings\n",
    "ENCODINGS_DIR = \"face_encodings/\"\n",
    "os.makedirs(ENCODINGS_DIR, exist_ok=True)\n",
    "\n",
    "# Load known face encodings and names\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "def load_encodings():\n",
    "    global known_face_encodings, known_face_names\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    for user_folder in os.listdir(ENCODINGS_DIR):\n",
    "        user_path = os.path.join(ENCODINGS_DIR, user_folder)\n",
    "        if os.path.isdir(user_path):\n",
    "            for file in os.listdir(user_path):\n",
    "                file_path = os.path.join(user_path, file)\n",
    "                image = face_recognition.load_image_file(file_path)\n",
    "                encodings = face_recognition.face_encodings(image)\n",
    "                if encodings:\n",
    "                    known_face_encodings.append(encodings[0])\n",
    "                    known_face_names.append(user_folder)\n",
    "\n",
    "# Function to insert new user data to Supabase\n",
    "def insert_to_supabase(name):\n",
    "    try:\n",
    "        response = supabase.table(\"faces\").insert({\"name\": name, \"access\": False}).execute()\n",
    "        \n",
    "        # Inspect the response\n",
    "        if not response.data:\n",
    "            raise Exception(\"Failed to insert data to Supabase. Response returned no data.\")\n",
    "        \n",
    "        print(f\"User {name} added to Supabase successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data to Supabase: {e}\")\n",
    "\n",
    "# Function to update user access in Supabase\n",
    "def update_access_in_supabase(name, access):\n",
    "    try:\n",
    "        response = supabase.table(\"faces\").update({\"access\": access}).eq(\"name\", name).execute()\n",
    "        \n",
    "        # Inspect the response\n",
    "        if not response.data:\n",
    "            raise Exception(\"Failed to update data in Supabase. Response returned no data.\")\n",
    "        \n",
    "        print(f\"Access for {name} updated to {access} in Supabase.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating data in Supabase: {e}\")\n",
    "\n",
    "# Function to save a new user's face encoding\n",
    "def save_user():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter the name of the new user:\")\n",
    "    if not name:\n",
    "        messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "        return\n",
    "\n",
    "    user_dir = os.path.join(ENCODINGS_DIR, name)\n",
    "    os.makedirs(user_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", f\"Capturing 10 frames for {name}. Look at the camera.\")\n",
    "\n",
    "    count = 0\n",
    "    while count < 10:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Display live feed\n",
    "        cv2.imshow(\"Save User - Capture Mode\", frame)\n",
    "\n",
    "        # Capture and save the frame\n",
    "        file_path = os.path.join(user_dir, f\"{name}_{count}.jpg\")\n",
    "        cv2.imwrite(file_path, frame)\n",
    "        count += 1\n",
    "        print(f\"Captured frame {count} for {name}\")\n",
    "\n",
    "        # Wait for 500ms before capturing the next frame\n",
    "        cv2.waitKey(1000)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Reload encodings after saving\n",
    "    load_encodings()\n",
    "\n",
    "    # Add the new user to Supabase with access default to False\n",
    "    insert_to_supabase(name)\n",
    "    messagebox.showinfo(\"Info\", f\"Frames captured and {name} added to the system.\")\n",
    "\n",
    "# Function for live face identification\n",
    "def live_identification():\n",
    "    active_names = set()\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", \"Press 'q' to quit live identification.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert frame to RGB (face_recognition expects RGB images)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect faces and their encodings\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        detected_names = set()\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # Default to Unknown\n",
    "            name = \"Unknown\"\n",
    "            access = False\n",
    "\n",
    "            # Compare with known faces\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "\n",
    "            if matches:\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "                    access = True\n",
    "\n",
    "            detected_names.add(name)\n",
    "\n",
    "            # Update user access in Supabase\n",
    "            if name != \"Unknown\":\n",
    "                update_access_in_supabase(name, access)\n",
    "\n",
    "            # Draw rectangle and label\n",
    "            color = (0, 255, 0) if access else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "        # Update access status for users not detected in this frame\n",
    "        for inactive_name in active_names - detected_names:\n",
    "            update_access_in_supabase(inactive_name, False)\n",
    "\n",
    "        active_names = detected_names\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Live Identification\", frame)\n",
    "\n",
    "        # Quit on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# GUI Application\n",
    "def main():\n",
    "    # Load encodings initially\n",
    "    load_encodings()\n",
    "\n",
    "    # Create a GUI window\n",
    "    root = Tk()\n",
    "    root.title(\"Face Recognition System\")\n",
    "\n",
    "    # Buttons for saving users and live identification\n",
    "    save_user_button = Button(\n",
    "        root, text=\"Save New User\", command=save_user, width=30, height=2\n",
    "    )\n",
    "    save_user_button.pack(pady=20)\n",
    "\n",
    "    live_identification_button = Button(\n",
    "        root, text=\"Live Identification\", command=live_identification, width=30, height=2\n",
    "    )\n",
    "    live_identification_button.pack(pady=20)\n",
    "\n",
    "    # Exit button to close the entire application\n",
    "    def exit_application():\n",
    "        root.destroy()  # Close the Tkinter window\n",
    "        os._exit(0)  # Terminate the Python program completely\n",
    "\n",
    "    exit_button = Button(root, text=\"Exit\", command=exit_application, width=30, height=2)\n",
    "    exit_button.pack(pady=20)\n",
    "\n",
    "    # Run the GUI event loop\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "from tkinter import Tk, Button, messagebox, simpledialog\n",
    "import numpy as np\n",
    "from supabase import create_client, Client\n",
    "\n",
    "# Supabase configuration\n",
    "SUPABASE_URL = \"https://puhexttrixwbmbmokekb.supabase.co\"\n",
    "SUPABASE_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InB1aGV4dHRyaXh3Ym1ibW9rZWtiIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzM2NzAwMTcsImV4cCI6MjA0OTI0NjAxN30.3SLnBspTZB0XA97d5rjrTpkV_JsFEmwRB9eXeULBdYY\"\n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_API_KEY)\n",
    "\n",
    "# Directory to store face encodings\n",
    "ENCODINGS_DIR = \"face_encodings/\"\n",
    "os.makedirs(ENCODINGS_DIR, exist_ok=True)\n",
    "\n",
    "# Load known face encodings and names\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "def load_encodings():\n",
    "    global known_face_encodings, known_face_names\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    for user_folder in os.listdir(ENCODINGS_DIR):\n",
    "        user_path = os.path.join(ENCODINGS_DIR, user_folder)\n",
    "        if os.path.isdir(user_path):\n",
    "            for file in os.listdir(user_path):\n",
    "                file_path = os.path.join(user_path, file)\n",
    "                image = face_recognition.load_image_file(file_path)\n",
    "                encodings = face_recognition.face_encodings(image)\n",
    "                if encodings:\n",
    "                    known_face_encodings.append(encodings[0])\n",
    "                    known_face_names.append(user_folder)\n",
    "\n",
    "# Function to insert new user data to Supabase\n",
    "def insert_to_supabase(name):\n",
    "    try:\n",
    "        response = supabase.table(\"faces\").insert({\"name\": name, \"access\": False}).execute()\n",
    "        \n",
    "        # Inspect the response\n",
    "        if not response.data:\n",
    "            raise Exception(\"Failed to insert data to Supabase. Response returned no data.\")\n",
    "        \n",
    "        print(f\"User {name} added to Supabase successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data to Supabase: {e}\")\n",
    "\n",
    "# Function to update user access in Supabase\n",
    "def update_access_in_supabase(name, access):\n",
    "    try:\n",
    "        response = supabase.table(\"faces\").update({\"access\": access}).eq(\"name\", name).execute()\n",
    "        \n",
    "        # Inspect the response\n",
    "        if not response.data:\n",
    "            raise Exception(\"Failed to update data in Supabase. Response returned no data.\")\n",
    "        \n",
    "        print(f\"Access for {name} updated to {access} in Supabase.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating data in Supabase: {e}\")\n",
    "\n",
    "# Function to save a new user's face encoding\n",
    "def save_user():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter the name of the new user:\")\n",
    "    if not name:\n",
    "        messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "        return\n",
    "\n",
    "    user_dir = os.path.join(ENCODINGS_DIR, name)\n",
    "    os.makedirs(user_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", f\"Capturing 10 frames for {name}. Look at the camera.\")\n",
    "\n",
    "    count = 0\n",
    "    while count < 10:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Display live feed\n",
    "        cv2.imshow(\"Save User - Capture Mode\", frame)\n",
    "\n",
    "        # Capture and save the frame\n",
    "        file_path = os.path.join(user_dir, f\"{name}_{count}.jpg\")\n",
    "        cv2.imwrite(file_path, frame)\n",
    "        count += 1\n",
    "        print(f\"Captured frame {count} for {name}\")\n",
    "\n",
    "        # Wait for 500ms before capturing the next frame\n",
    "        cv2.waitKey(1000)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Reload encodings after saving\n",
    "    load_encodings()\n",
    "\n",
    "    # Add the new user to Supabase with access default to False\n",
    "    insert_to_supabase(name)\n",
    "    messagebox.showinfo(\"Info\", f\"Frames captured and {name} added to the system.\")\n",
    "\n",
    "# Function for live face identification\n",
    "def live_identification():\n",
    "    active_names = set()\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", \"Press 'q' to quit live identification.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert frame to RGB (face_recognition expects RGB images)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect faces and their encodings\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        detected_names = set()\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # Default to Unknown\n",
    "            name = \"Unknown\"\n",
    "            access = False\n",
    "\n",
    "            # Compare with known faces\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "\n",
    "            if matches:\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "                    access = True\n",
    "\n",
    "            detected_names.add(name)\n",
    "\n",
    "            # Update user access in Supabase\n",
    "            if name != \"Unknown\":\n",
    "                update_access_in_supabase(name, access)\n",
    "\n",
    "            # Draw rectangle and label\n",
    "            color = (0, 255, 0) if access else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "        # Update access status for users not detected in this frame\n",
    "        for inactive_name in active_names - detected_names:\n",
    "            update_access_in_supabase(inactive_name, False)\n",
    "\n",
    "        active_names = detected_names\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Live Identification\", frame)\n",
    "\n",
    "        # Quit on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# GUI Application\n",
    "def main():\n",
    "    # Load encodings initially\n",
    "    load_encodings()\n",
    "\n",
    "    # Create a GUI window\n",
    "    root = Tk()\n",
    "    root.title(\"Face Recognition System\")\n",
    "\n",
    "    # Buttons for saving users and live identification\n",
    "    save_user_button = Button(\n",
    "        root, text=\"Save New User\", command=save_user, width=30, height=2\n",
    "    )\n",
    "    save_user_button.pack(pady=20)\n",
    "\n",
    "    live_identification_button = Button(\n",
    "        root, text=\"Live Identification\", command=live_identification, width=30, height=2\n",
    "    )\n",
    "    live_identification_button.pack(pady=20)\n",
    "\n",
    "    # Exit button to close the entire application\n",
    "    def exit_application():\n",
    "        root.destroy()  # Close the Tkinter window\n",
    "        os._exit(0)  # Terminate the Python program completely\n",
    "\n",
    "    exit_button = Button(root, text=\"Exit\", command=exit_application, width=30, height=2)\n",
    "    exit_button.pack(pady=20)\n",
    "\n",
    "    # Run the GUI event loop\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\RVPsy\\AppData\\Local\\Temp\\ipykernel_13056\\997099887.py\", line 210, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\RVPsy\\AppData\\Local\\Temp\\ipykernel_13056\\997099887.py\", line 181, in main\n",
      "    load_encodings()\n",
      "  File \"C:\\Users\\RVPsy\\AppData\\Local\\Temp\\ipykernel_13056\\997099887.py\", line 33, in load_encodings\n",
      "    encodings = face_recognition.face_encodings(image)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\face_recognition\\api.py\", line 214, in face_encodings\n",
      "    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set, num_jitters)) for raw_landmark_set in raw_landmarks]\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\face_recognition\\api.py\", line 214, in <listcomp>\n",
      "    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set, num_jitters)) for raw_landmark_set in raw_landmarks]\n",
      "RuntimeError: Error while calling perf_results[0].status in file D:\\bld\\dlib-split_1726093520894\\work\\dlib\\cuda\\cudnn_dlibapi.cpp:768. code: 4003, reason: CUDA Resources could not be allocated.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1160, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\stack_data\\utils.py\", line 83, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\executing\\executing.py\", line 264, in executing\n",
      "    source = cls.for_frame(frame)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\executing\\executing.py\", line 183, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\executing\\executing.py\", line 212, in for_filename\n",
      "    return cls._for_filename_and_lines(filename, tuple(lines))\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\executing\\executing.py\", line 223, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\site-packages\\executing\\executing.py\", line 163, in __init__\n",
      "    self.tree = ast.parse(self.text, filename=filename)\n",
      "  File \"c:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\ast.py\", line 50, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "MemoryError\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "from tkinter import Tk, Button, messagebox, simpledialog\n",
    "import numpy as np\n",
    "from supabase import create_client, Client\n",
    "\n",
    "# Supabase configuration\n",
    "SUPABASE_URL = \"https://puhexttrixwbmbmokekb.supabase.co\"\n",
    "SUPABASE_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InB1aGV4dHRyaXh3Ym1ibW9rZWtiIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzM2NzAwMTcsImV4cCI6MjA0OTI0NjAxN30.3SLnBspTZB0XA97d5rjrTpkV_JsFEmwRB9eXeULBdYY\"\n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_API_KEY)\n",
    "\n",
    "# Directory to store face encodings\n",
    "ENCODINGS_DIR = \"face_encodings/\"\n",
    "os.makedirs(ENCODINGS_DIR, exist_ok=True)\n",
    "\n",
    "# Load known face encodings and names\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "def load_encodings():\n",
    "    global known_face_encodings, known_face_names\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    for user_folder in os.listdir(ENCODINGS_DIR):\n",
    "        user_path = os.path.join(ENCODINGS_DIR, user_folder)\n",
    "        if os.path.isdir(user_path):\n",
    "            for file in os.listdir(user_path):\n",
    "                file_path = os.path.join(user_path, file)\n",
    "                image = face_recognition.load_image_file(file_path)\n",
    "                encodings = face_recognition.face_encodings(image)\n",
    "                if encodings:\n",
    "                    known_face_encodings.append(encodings[0])\n",
    "                    known_face_names.append(user_folder)\n",
    "\n",
    "# Function to insert new user data to Supabase\n",
    "def insert_to_supabase(name):\n",
    "    try:\n",
    "        response = supabase.table(\"faces\").insert({\"name\": name, \"access\": False}).execute()\n",
    "        \n",
    "        # Inspect the response\n",
    "        if not response.data:\n",
    "            raise Exception(\"Failed to insert data to Supabase. Response returned no data.\")\n",
    "        \n",
    "        print(f\"User {name} added to Supabase successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data to Supabase: {e}\")\n",
    "\n",
    "# Function to update user access in Supabase\n",
    "def update_access_in_supabase(name, access):\n",
    "    try:\n",
    "        response = supabase.table(\"faces\").update({\"access\": access}).eq(\"name\", name).execute()\n",
    "        \n",
    "        # Inspect the response\n",
    "        if not response.data:\n",
    "            raise Exception(\"Failed to update data in Supabase. Response returned no data.\")\n",
    "        \n",
    "        print(f\"Access for {name} updated to {access} in Supabase.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating data in Supabase: {e}\")\n",
    "\n",
    "# Function to save a new user's face encoding\n",
    "def save_user():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter the name of the new user:\")\n",
    "    if not name:\n",
    "        messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "        return\n",
    "\n",
    "    user_dir = os.path.join(ENCODINGS_DIR, name)\n",
    "    os.makedirs(user_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", f\"Capturing 10 frames for {name}. Look at the camera.\")\n",
    "\n",
    "    count = 0\n",
    "    while count < 10:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Display live feed\n",
    "        cv2.imshow(\"Save User - Capture Mode\", frame)\n",
    "\n",
    "        # Capture and save the frame\n",
    "        file_path = os.path.join(user_dir, f\"{name}_{count}.jpg\")\n",
    "        cv2.imwrite(file_path, frame)\n",
    "        count += 1\n",
    "        print(f\"Captured frame {count} for {name}\")\n",
    "\n",
    "        # Wait for 500ms before capturing the next frame\n",
    "        cv2.waitKey(1000)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Reload encodings after saving\n",
    "    load_encodings()\n",
    "\n",
    "    # Add the new user to Supabase with access default to False\n",
    "    insert_to_supabase(name)\n",
    "    messagebox.showinfo(\"Info\", f\"Frames captured and {name} added to the system.\")\n",
    "\n",
    "# Function for live face identification\n",
    "def live_identification():\n",
    "    active_names = set()\n",
    "    cap = cv2.VideoCapture(2)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", \"Press 'q' to quit live identification.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert frame to RGB (face_recognition expects RGB images)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect faces and their encodings\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        detected_names = set()\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # Default to Unknown\n",
    "            name = \"Unknown\"\n",
    "            access = False\n",
    "\n",
    "            # Compare with known faces\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "\n",
    "            if matches:\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "                    access = True\n",
    "\n",
    "            detected_names.add(name)\n",
    "\n",
    "            # Update user access in Supabase\n",
    "            if name != \"Unknown\":\n",
    "                update_access_in_supabase(name, access)\n",
    "\n",
    "            # Draw rectangle and label\n",
    "            color = (0, 255, 0) if access else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "        # Update access status for users not detected in this frame\n",
    "        for inactive_name in active_names - detected_names:\n",
    "            update_access_in_supabase(inactive_name, False)\n",
    "\n",
    "        active_names = detected_names\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Live Identification\", frame)\n",
    "\n",
    "        # Quit on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# GUI Application\n",
    "def main():\n",
    "    # Load encodings initially\n",
    "    load_encodings()\n",
    "\n",
    "    # Create a GUI window\n",
    "    root = Tk()\n",
    "    root.title(\"Face Recognition System\")\n",
    "\n",
    "    # Buttons for saving users and live identification\n",
    "    save_user_button = Button(\n",
    "        root, text=\"Save New User\", command=save_user, width=30, height=2\n",
    "    )\n",
    "    save_user_button.pack(pady=20)\n",
    "\n",
    "    live_identification_button = Button(\n",
    "        root, text=\"Live Identification\", command=live_identification, width=30, height=2\n",
    "    )\n",
    "    live_identification_button.pack(pady=20)\n",
    "\n",
    "    # Exit button to close the entire application\n",
    "    def exit_application():\n",
    "        root.destroy()  # Close the Tkinter window\n",
    "        os._exit(0)  # Terminate the Python program completely\n",
    "\n",
    "    exit_button = Button(root, text=\"Exit\", command=exit_application, width=30, height=2)\n",
    "    exit_button.pack(pady=20)\n",
    "\n",
    "    # Run the GUI event loop\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured frame 1 for ali\n",
      "Captured frame 2 for ali\n",
      "Captured frame 3 for ali\n",
      "Captured frame 4 for ali\n",
      "Captured frame 5 for ali\n",
      "Captured frame 6 for ali\n",
      "Captured frame 7 for ali\n",
      "Captured frame 8 for ali\n",
      "Captured frame 9 for ali\n",
      "Captured frame 10 for ali\n",
      "Error inserting data to Supabase: [Errno 11001] getaddrinfo failed\n",
      "Captured frame 1 for ali\n",
      "Captured frame 2 for ali\n",
      "Captured frame 3 for ali\n",
      "Captured frame 4 for ali\n",
      "Captured frame 5 for ali\n",
      "Captured frame 6 for ali\n",
      "Captured frame 7 for ali\n",
      "Captured frame 8 for ali\n",
      "Captured frame 9 for ali\n",
      "Captured frame 10 for ali\n",
      "User ali added to Supabase successfully.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to False.\n",
      "Access for ali updated to True.\n",
      "Error updating data in Supabase: Failed to update data in Supabase.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to True.\n",
      "Access for ali updated to False.\n",
      "Error updating data in Supabase: Failed to update data in Supabase.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 169\u001b[0m\n\u001b[0;32m    166\u001b[0m     root\u001b[38;5;241m.\u001b[39mmainloop()\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 169\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 166\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    163\u001b[0m Button(root, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLive Identification\u001b[39m\u001b[38;5;124m\"\u001b[39m, command\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: live_identification(\u001b[38;5;241m0.65\u001b[39m), width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mpack(pady\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m    164\u001b[0m Button(root, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExit\u001b[39m\u001b[38;5;124m\"\u001b[39m, command\u001b[38;5;241m=\u001b[39mroot\u001b[38;5;241m.\u001b[39mdestroy, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mpack(pady\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m--> 166\u001b[0m \u001b[43mroot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\RVPsy\\anaconda3\\envs\\yolov9\\lib\\tkinter\\__init__.py:1429\u001b[0m, in \u001b[0;36mMisc.mainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "from tkinter import Tk, Button, messagebox, simpledialog\n",
    "import numpy as np\n",
    "from supabase import create_client, Client\n",
    "\n",
    "# Supabase configuration\n",
    "SUPABASE_URL = \"https://puhexttrixwbmbmokekb.supabase.co\"\n",
    "SUPABASE_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InB1aGV4dHRyaXh3Ym1ibW9rZWtiIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzM2NzAwMTcsImV4cCI6MjA0OTI0NjAxN30.3SLnBspTZB0XA97d5rjrTpkV_JsFEmwRB9eXeULBdYY\"\n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_API_KEY)\n",
    "\n",
    "# Directory to store face encodings\n",
    "ENCODINGS_DIR = \"face_encodings/\"\n",
    "os.makedirs(ENCODINGS_DIR, exist_ok=True)\n",
    "\n",
    "# Known face encodings and names\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "def load_encodings():\n",
    "    global known_face_encodings, known_face_names\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    for user_folder in os.listdir(ENCODINGS_DIR):\n",
    "        user_path = os.path.join(ENCODINGS_DIR, user_folder)\n",
    "        if os.path.isdir(user_path):\n",
    "            for file in os.listdir(user_path):\n",
    "                file_path = os.path.join(user_path, file)\n",
    "                image = face_recognition.load_image_file(file_path)\n",
    "                encodings = face_recognition.face_encodings(image)\n",
    "                if encodings:\n",
    "                    known_face_encodings.append(encodings[0])\n",
    "                    known_face_names.append(user_folder)\n",
    "\n",
    "# Insert user data to Supabase\n",
    "def insert_to_supabase(name):\n",
    "    try:\n",
    "        response = supabase.table(\"faces\").insert({\"name\": name, \"access\": False}).execute()\n",
    "        if not response.data:\n",
    "            raise Exception(\"Failed to insert data to Supabase.\")\n",
    "        print(f\"User {name} added to Supabase successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting data to Supabase: {e}\")\n",
    "\n",
    "# Update user access in Supabase\n",
    "def update_access_in_supabase(name, access):\n",
    "    try:\n",
    "        response = supabase.table(\"faces\").update({\"access\": access}).eq(\"name\", name).execute()\n",
    "        if not response.data:\n",
    "            raise Exception(\"Failed to update data in Supabase.\")\n",
    "        print(f\"Access for {name} updated to {access}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating data in Supabase: {e}\")\n",
    "\n",
    "# Calculate accuracy and check against threshold\n",
    "def is_match(face_encoding, known_encodings, threshold=0.65):\n",
    "    face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "    best_match_index = np.argmin(face_distances)\n",
    "    accuracy = 1 - face_distances[best_match_index]\n",
    "    if accuracy >= threshold:\n",
    "        return best_match_index, accuracy\n",
    "    return -1, None\n",
    "\n",
    "# Live face identification with threshold\n",
    "def live_identification(threshold=0.65):\n",
    "    active_names = set()\n",
    "    cap = cv2.VideoCapture(3)\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", \"Press 'q' to quit live identification.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        detected_names = set()\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            match_index, accuracy = is_match(face_encoding, known_face_encodings, threshold)\n",
    "            name = \"Unknown\"\n",
    "            access = False\n",
    "\n",
    "            if match_index != -1:\n",
    "                name = known_face_names[match_index]\n",
    "                access = True\n",
    "\n",
    "            detected_names.add(name)\n",
    "            if name != \"Unknown\":\n",
    "                update_access_in_supabase(name, access)\n",
    "\n",
    "            # Draw rectangle and label\n",
    "            color = (0, 255, 0) if access else (0, 0, 255)\n",
    "            label = f\"{name} ({accuracy:.2%})\" if access else \"Unknown\"\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "            cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "        for inactive_name in active_names - detected_names:\n",
    "            update_access_in_supabase(inactive_name, False)\n",
    "\n",
    "        active_names = detected_names\n",
    "        cv2.imshow(\"Live Identification\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Save a new user's face encoding\n",
    "def save_user():\n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter the name of the new user:\")\n",
    "    if not name:\n",
    "        messagebox.showerror(\"Error\", \"Name cannot be empty!\")\n",
    "        return\n",
    "\n",
    "    user_dir = os.path.join(ENCODINGS_DIR, name)\n",
    "    os.makedirs(user_dir, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(3)\n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Camera not accessible!\")\n",
    "        return\n",
    "\n",
    "    messagebox.showinfo(\"Info\", f\"Capturing 10 frames for {name}. Look at the camera.\")\n",
    "\n",
    "    count = 0\n",
    "    while count < 10:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        cv2.imshow(\"Save User - Capture Mode\", frame)\n",
    "        file_path = os.path.join(user_dir, f\"{name}_{count}.jpg\")\n",
    "        cv2.imwrite(file_path, frame)\n",
    "        count += 1\n",
    "        print(f\"Captured frame {count} for {name}\")\n",
    "        cv2.waitKey(1000)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    load_encodings()\n",
    "    insert_to_supabase(name)\n",
    "    messagebox.showinfo(\"Info\", f\"Frames captured and {name} added.\")\n",
    "\n",
    "# GUI Application\n",
    "def main():\n",
    "    load_encodings()\n",
    "    root = Tk()\n",
    "    root.title(\"Face Recognition System\")\n",
    "\n",
    "    Button(root, text=\"Save New User\", command=save_user, width=30, height=2).pack(pady=20)\n",
    "    Button(root, text=\"Live Identification\", command=lambda: live_identification(0.65), width=30, height=2).pack(pady=20)\n",
    "    Button(root, text=\"Exit\", command=root.destroy, width=30, height=2).pack(pady=20)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
